{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepONet for Acoustic Wave Propagation\n",
    "\n",
    "**PhD Autumn School - Scientific Machine Learning**\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this 1-hour hands-on exercise, you will:\n",
    "1. Understand the DeepONet architecture for operator learning\n",
    "1. Understand the data.\n",
    "2. Compare different activation functions (ReLU vs Sine)\n",
    "3. Investigate the impact of Fourier feature expansions\n",
    "\n",
    "## Introduction to DeepONet\n",
    "\n",
    "**Deep Operator Networks (DeepONet)** learn operators that map functions to functions, rather than just vectors to vectors like traditional neural networks.\n",
    "\n",
    "### The Problem\n",
    "\n",
    "In acoustic wave propagation, we want to learn the operator $\\mathcal{G}$ that maps:\n",
    "- **Input function** $u(x)$: Initial pressure distribution (source configuration)\n",
    "- **Output function** $s(x, y, t)$: Pressure field at any location $(x, y)$ and time $t$\n",
    "\n",
    "Mathematically: $s = \\mathcal{G}(u)$\n",
    "\n",
    "### DeepONet Architecture\n",
    "\n",
    "```\n",
    "                    ┌─────────────┐\n",
    "u(x) ─────────────> │ Branch Net  │ ───> [b₁, b₂, ..., bₚ]\n",
    "  (function)        └─────────────┘            │\n",
    "                                               │\n",
    "                                               ├──> Inner Product ──> s(y)\n",
    "                                               │\n",
    "y = (x,y,t) ────> ┌─────────────┐            │\n",
    "  (coordinates)   │  Trunk Net  │ ───> [t₁, t₂, ..., tₚ]\n",
    "                  └─────────────┘\n",
    "```\n",
    "\n",
    "- **Branch network**: Encodes the input function $u$ into a latent representation\n",
    "- **Trunk network**: Encodes the query coordinates $(x, y, t)$\n",
    "- **Inner product**: Combines both representations: $s(y) = \\sum_{i=1}^{p} b_i(u) \\cdot t_i(y) + b_0$\n",
    "\n",
    "### Key Insight\n",
    "\n",
    "By learning this decomposition, the network can:\n",
    "- Generalize to new source configurations $u$ (never seen during training)\n",
    "- Evaluate at arbitrary query locations $(x, y, t)$\n",
    "- Reduce computational cost compared to traditional PDE solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from deeponet_acoustics.datahandlers.datagenerators import (\n",
    "    DataH5Compact,\n",
    "    DatasetStreamer,\n",
    "    pytorch_collate,  # PyTorch collator for data loading\n",
    ")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Update these paths to point to your data\n",
    "# simpe 2D domain\n",
    "train_data_path = \"/Users/nikolasborrel/data/deeponet/data/input2D/rect2x2_freq_indep_ppw_2_6_2_5_train\"\n",
    "data_val_path = (\n",
    "    \"/Users/nikolasborrel/data/deeponet/data/input2D/rect2x2_freq_indep_ppw_2_4_2_val\"\n",
    ")\n",
    "test_data_path = (\n",
    "    \"/Users/nikolasborrel/data/deeponet/data/input2D/rect2x2_freq_indep_ppw_2_4_2_test\"\n",
    ")\n",
    "\n",
    "# furnished room\n",
    "# train_data_path = \"/Users/nikolasborrel/data/deeponet/data/input2D/rect3x3_furn_freq_indep_ppw_2_6_2_3_train\"\n",
    "# data_val_path = \"/Users/nikolasborrel/data/deeponet/data/input2D/rect3x3_furn_freq_indep_ppw_2_4_2_val\"\n",
    "# test_data_path = \"/Users/nikolasborrel/data/deeponet/data/input2D/rect3x3_furn_freq_indep_ppw_2_4_2_val\"\n",
    "\n",
    "# Load training data\n",
    "data_train = DataH5Compact(\n",
    "    train_data_path,\n",
    "    t_norm=343.0,  # Speed of sound for normalization\n",
    "    flatten_ic=True,  # Flatten initial conditions (for MLPs)\n",
    "    norm_data=True,  # Normalize spatial coordinates\n",
    "    u_p_range=(\n",
    "        -2.0,\n",
    "        2.0,\n",
    "    ),  # Model was tuned with this branch normalization in the paper\n",
    ")\n",
    "\n",
    "# Load val data\n",
    "data_val = DataH5Compact(\n",
    "    data_val_path,\n",
    "    t_norm=343.0,\n",
    "    flatten_ic=True,\n",
    "    norm_data=True,\n",
    "    u_p_range=(-2.0, 2.0),\n",
    ")\n",
    "\n",
    "print(f\"Training sources: {data_train.N}\")\n",
    "print(f\"Val sources: {data_val.N}\")\n",
    "print(f\"Mesh points: {data_train.P_mesh}\")\n",
    "print(f\"Time steps: {len(data_train.tsteps)}\")\n",
    "print(f\"Input (u) shape: {data_train.u_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "batch_size_branch = 64  # Number of different sources per batch\n",
    "batch_size_coord = 200  # Number of coordinate points per batch\n",
    "\n",
    "dataset_train = DatasetStreamer(data_train, batch_size_coord=batch_size_coord)\n",
    "dataset_val = DatasetStreamer(data_val, batch_size_coord=batch_size_coord)\n",
    "\n",
    "\n",
    "# Use pytorch_collate to convert to PyTorch tensors\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=min(batch_size_branch, dataset_train.N),\n",
    "    shuffle=True,\n",
    "    collate_fn=pytorch_collate,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=min(batch_size_branch, dataset_val.N),\n",
    "    shuffle=False,\n",
    "    collate_fn=pytorch_collate,\n",
    ")\n",
    "\n",
    "# Get a sample batch to understand dimensions\n",
    "sample_batch = next(iter(dataloader_train))\n",
    "(u_sample, y_sample), s_sample, _, _ = sample_batch\n",
    "\n",
    "print(\"\\nBatch shapes:\")\n",
    "print(f\"  u (branch input): {u_sample.shape}  # [batch_branch, u_dim]\")\n",
    "print(\n",
    "    f\"  y (trunk input):  {y_sample.shape}  # [batch_branch, batch_coord, coord_dim (including time dim)]\"\n",
    ")\n",
    "print(f\"  s (output):       {s_sample.shape}  # [batch_branch, batch_coord]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations\n",
    "\n",
    "Let's visualize the training and test data to understand the acoustic wave propagation problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeponet_acoustics.datahandlers.datagenerators import _normalize_spatial\n",
    "\n",
    "\n",
    "def plot_initial_condition(data: DataH5Compact, source_idx=0, figsize=(8, 6)):\n",
    "    \"\"\"\n",
    "    Plot the initial pressure distribution (source configuration).\n",
    "\n",
    "    Args:\n",
    "        data: DataH5Compact instance\n",
    "        source_idx: Index of source to visualize\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    # Get initial condition\n",
    "    dataset = data.datasets[source_idx]\n",
    "    u = dataset[data.tag_ufield][:]\n",
    "\n",
    "    # Get umesh coordinates (the mesh for initial conditions - different from simulation mesh!)\n",
    "    umesh = dataset[\"/umesh\"][:]\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    scatter = ax.scatter(\n",
    "        umesh[:, 0], umesh[:, 1], c=u, cmap=\"RdBu_r\", s=20, vmin=-2, vmax=2\n",
    "    )\n",
    "\n",
    "    # Get source position if available\n",
    "    if \"source_position\" in dataset:\n",
    "        x0 = dataset[\"source_position\"][:]\n",
    "        ax.plot(x0[0], x0[1], \"k*\", markersize=20)\n",
    "        ax.legend()\n",
    "\n",
    "    plt.colorbar(scatter, ax=ax, label=\"Initial Pressure\")\n",
    "    ax.set_xlabel(\"x [m]\")\n",
    "    ax.set_ylabel(\"y [m]\")\n",
    "    ax.set_title(f\"Initial Condition (Source {source_idx})\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"NOTE: that the coordinates for U are not used and hence not normalized.\")\n",
    "    print(f\"Initial condition range: [{np.min(u):.3f}, {np.max(u):.3f}]\")\n",
    "    print(f\"Number of IC points (umesh): {len(u)}\")\n",
    "    print(f\"Number of simulation points (mesh): {len(data.mesh)}\")\n",
    "\n",
    "\n",
    "def plot_pressure_field_snapshots(\n",
    "    data: DataH5Compact, source_idx=0, time_indices=[0, 30, 60, 90], figsize=(16, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot pressure field at multiple time steps.\n",
    "\n",
    "    Args:\n",
    "        data: DataH5Compact instance\n",
    "        source_idx: Index of source to visualize\n",
    "        time_indices: List of time step indices to plot\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    dataset = data.datasets[source_idx]\n",
    "\n",
    "    # Get pressure field\n",
    "    pressure_field = dataset[data.tags_field[0]][:, :: data.data_prune]  # [time, space]\n",
    "\n",
    "    # Create subplots\n",
    "    n_plots = len(time_indices)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=figsize)\n",
    "\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Global colorbar limits\n",
    "    vmin, vmax = -0.5, 0.5\n",
    "\n",
    "    for i, (ax, t_idx) in enumerate(zip(axes, time_indices)):\n",
    "        # Get pressure at this time step\n",
    "        p_t = pressure_field[t_idx, :]\n",
    "\n",
    "        # Plot\n",
    "        scatter = ax.scatter(\n",
    "            data.mesh[:, 0],\n",
    "            data.mesh[:, 1],\n",
    "            c=p_t,\n",
    "            cmap=\"RdBu_r\",\n",
    "            s=10,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "\n",
    "        # Mark source position if available\n",
    "        if \"source_position\" in dataset:\n",
    "            x0 = dataset[\"source_position\"][:]\n",
    "            # Source coordinates are not normalized (not used for training)\n",
    "            if data.normalize_data:\n",
    "                x0 = _normalize_spatial(x0, data.xmin_phys, data.xmax_phys)\n",
    "            ax.plot(x0[0], x0[1], \"k*\", markersize=15)\n",
    "\n",
    "        # Get actual time value\n",
    "        time_val = data.tsteps[t_idx]\n",
    "\n",
    "        ax.set_title(f\"t_norm = {time_val:.2f}\")\n",
    "        ax.set_xlabel(\"x [m]\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"y [m]\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Add shared colorbar\n",
    "    fig.colorbar(scatter, ax=axes, label=\"Pressure\", pad=0.02)\n",
    "    fig.suptitle(f\"Pressure Field Evolution (Source {source_idx})\", y=1.02, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"t_norm min/max: {data.tsteps[0]}/{data.tsteps[-1]}\")\n",
    "\n",
    "\n",
    "def plot_multiple_sources(\n",
    "    data: DataH5Compact, source_indices=[0, 1, 2], time_idx=50, figsize=(15, 4)\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare pressure fields from different source positions at the same time.\n",
    "\n",
    "    Args:\n",
    "        data: DataH5Compact instance\n",
    "        source_indices: List of source indices to compare\n",
    "        time_idx: Time step index to visualize\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "\n",
    "    mesh_vis = data.mesh\n",
    "\n",
    "    # Create subplots\n",
    "    n_plots = len(source_indices)\n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=figsize)\n",
    "\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Global colorbar limits\n",
    "    vmin, vmax = -0.5, 0.5\n",
    "\n",
    "    for i, (ax, src_idx) in enumerate(zip(axes, source_indices)):\n",
    "        if src_idx >= data.N:\n",
    "            ax.text(\n",
    "                0.5,\n",
    "                0.5,\n",
    "                f\"Source {src_idx}\\nnot available\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                transform=ax.transAxes,\n",
    "            )\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            continue\n",
    "\n",
    "        dataset = data.datasets[src_idx]\n",
    "        pressure_field = dataset[data.tags_field[0]][:, :: data.data_prune]\n",
    "        p_t = pressure_field[time_idx, :]\n",
    "\n",
    "        # Plot\n",
    "        scatter = ax.scatter(\n",
    "            mesh_vis[:, 0],\n",
    "            mesh_vis[:, 1],\n",
    "            c=p_t,\n",
    "            cmap=\"RdBu_r\",\n",
    "            s=10,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "\n",
    "        # Mark source position if available\n",
    "        if \"source_position\" in dataset:\n",
    "            x0 = dataset[\"source_position\"][:]\n",
    "            # Source coordinates are not normalized (not used for training)\n",
    "            if data.normalize_data:\n",
    "                x0 = _normalize_spatial(x0, data.xmin_phys, data.xmax_phys)\n",
    "            ax.plot(x0[0], x0[1], \"k*\", markersize=15)\n",
    "\n",
    "        ax.set_title(f\"Source {src_idx}\")\n",
    "        ax.set_xlabel(\"x [m]\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"y [m]\")\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Add shared colorbar\n",
    "    fig.colorbar(scatter, ax=axes, label=\"Pressure\", pad=0.02)\n",
    "\n",
    "    time_val = data.tsteps[time_idx]\n",
    "    fig.suptitle(f\"Pressure Fields at t_norm = {time_val:.4f}\", y=1.02, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the 2D Acoustic Data\n",
    "\n",
    "Before training, let's understand what the data looks like by creating visualization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize initial condition from training data (only 1 source available)\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING DATA - Initial Condition\")\n",
    "print(\"=\" * 60)\n",
    "plot_initial_condition(data_train, source_idx=0)\n",
    "\n",
    "# Visualize pressure field evolution from val data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION DATA - Pressure Field Evolution\")\n",
    "print(\"=\" * 60)\n",
    "plot_pressure_field_snapshots(data_val, source_idx=0, time_indices=[10, 40, 70, 95])\n",
    "\n",
    "# Compare different source positions from test data\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VALIDATION DATA - Multiple Source Positions\")\n",
    "print(\"=\" * 60)\n",
    "plot_multiple_sources(data_val, source_indices=[0, 1, 2], time_idx=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fourier Feature Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_feature_expansion(freqs=[]):\n",
    "    \"\"\"\n",
    "    Create a Fourier feature expansion function.\n",
    "\n",
    "    Args:\n",
    "        freqs: List of frequencies for Fourier features\n",
    "               Empty list means no Fourier features (just return input)\n",
    "\n",
    "    Returns:\n",
    "        Function that applies Fourier feature expansion\n",
    "    \"\"\"\n",
    "    if len(freqs) == 0:\n",
    "        return lambda y: y\n",
    "\n",
    "    def expand(y):\n",
    "        # y shape: [batch, coord_dim] or [batch, n_points, coord_dim]\n",
    "        features = [y]\n",
    "        for f in freqs:\n",
    "            features.append(np.cos(2 * np.pi * f * y))\n",
    "            features.append(np.sin(2 * np.pi * f * y))\n",
    "        return np.concatenate(features, axis=-1)\n",
    "\n",
    "    return expand\n",
    "\n",
    "\n",
    "# Example: no Fourier features\n",
    "feat_fn_none = fourier_feature_expansion(freqs=[])\n",
    "\n",
    "# Example: with Fourier features at specific frequencies\n",
    "feat_fn_fourier = fourier_feature_expansion(freqs=[1.0, 2.0])\n",
    "\n",
    "# Test\n",
    "test_input = np.random.rand(4, 3)  # [batch=4, coord_dim=3]\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Without Fourier features: {feat_fn_none(test_input).shape}\")\n",
    "print(f\"With Fourier features: {feat_fn_fourier(test_input).shape}  # 3 + 2*2*3 = 15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Network Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sinusoidal Weight Initialization\n",
    "\n",
    "For sine activations, proper weight initialization is CRITICAL.\n",
    "Standard initializations (Xavier, He) don't work well with periodic activations.\n",
    "\n",
    "Key parameters from JAX implementation (networks_flax.py):\n",
    "- First layer: uniform(-1/d_in, 1/d_in)\n",
    "- Hidden layers: uniform(-sqrt(6/d_in)/30, sqrt(6/d_in)/30)\n",
    "- Angular frequency: 30.0 (scales first layer input)\n",
    "\n",
    "Reference: SIREN paper (https://arxiv.org/abs/2006.09661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def sinusoidal_init_(\n",
    "    weights: torch.Tensor, is_first_layer=False, angular_freq=30\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Initialize weights for networks with sine activations.\n",
    "\n",
    "    Args:\n",
    "        weights: PyTorch weight tensor with shape [out_features, in_features]\n",
    "        is_first_layer: Use different range for first layer\n",
    "        angular_freq: Angular frequency (default: 30)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # IMPORTANT: PyTorch Linear weights have shape [out_features, in_features]\n",
    "        # So shape[1] is the input dimension (d_in), NOT shape[0] as in Jax!\n",
    "        d_in = weights.shape[1]  # Input features (correct for PyTorch)\n",
    "\n",
    "        if is_first_layer:\n",
    "            bound = 1.0 / d_in\n",
    "        else:\n",
    "            bound = math.sqrt(6.0 / d_in) / angular_freq\n",
    "\n",
    "        weights.uniform_(-bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BranchNet and TrunkNet classes with sine initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BranchNet(nn.Module):\n",
    "    \"\"\"Branch network with optional sine activation support.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_hidden_layers,\n",
    "        activation=\"relu\",\n",
    "        angular_freq=30.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.angular_freq = angular_freq if activation == \"sine\" else 1.0\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # First layer\n",
    "        first_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        if activation == \"sine\":\n",
    "            sinusoidal_init_(first_layer.weight, is_first_layer=True)\n",
    "        layers.append(first_layer)\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "            if activation == \"sine\":\n",
    "                sinusoidal_init_(\n",
    "                    layer.weight, is_first_layer=False, angular_freq=angular_freq\n",
    "                )\n",
    "            layers.append(layer)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        if activation == \"sine\":\n",
    "            sinusoidal_init_(\n",
    "                output_layer.weight, is_first_layer=False, angular_freq=angular_freq\n",
    "            )\n",
    "        layers.append(output_layer)\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # Select activation\n",
    "        if activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == \"sine\":\n",
    "            self.activation = lambda x: torch.sin(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation}\")\n",
    "\n",
    "    def forward(self, u):\n",
    "        x = u\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # Apply angular frequency scaling to FIRST layer input (for sine networks)\n",
    "            if i == 0:\n",
    "                x = layer(self.angular_freq * x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "            # Apply activation (except last layer)\n",
    "            if i < len(self.layers) - 1:\n",
    "                x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrunkNet(nn.Module):\n",
    "    \"\"\"Trunk network with optional sine activation support.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_hidden_layers,\n",
    "        activation=\"relu\",\n",
    "        angular_freq=30.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.angular_freq = angular_freq if activation == \"sine\" else 1.0\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # First layer\n",
    "        first_layer = nn.Linear(input_dim, hidden_dim)\n",
    "        if activation == \"sine\":\n",
    "            sinusoidal_init_(first_layer.weight, is_first_layer=True)\n",
    "        layers.append(first_layer)\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "            if activation == \"sine\":\n",
    "                sinusoidal_init_(\n",
    "                    layer.weight, is_first_layer=False, angular_freq=angular_freq\n",
    "                )\n",
    "            layers.append(layer)\n",
    "\n",
    "        # Output layer\n",
    "        output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "        if activation == \"sine\":\n",
    "            sinusoidal_init_(\n",
    "                output_layer.weight, is_first_layer=False, angular_freq=angular_freq\n",
    "            )\n",
    "        layers.append(output_layer)\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # Select activation\n",
    "        if activation == \"relu\":\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation == \"sine\":\n",
    "            self.activation = lambda x: torch.sin(x)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown activation: {activation}\")\n",
    "\n",
    "    def forward(self, y):\n",
    "        x = y\n",
    "\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            # Apply angular frequency scaling to FIRST layer input (for sine networks)\n",
    "            if i == 0:\n",
    "                x = layer(self.angular_freq * x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "            # Apply activation (except last layer)\n",
    "            if i < len(self.layers) - 1:\n",
    "                x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DeepONet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep Operator Network combining branch and trunk networks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, branch_net, trunk_net):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            branch_net: Branch network (BranchNet instance)\n",
    "            trunk_net: Trunk network (TrunkNet instance)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.branch_net = branch_net\n",
    "        self.trunk_net = trunk_net\n",
    "\n",
    "        # Learnable bias term\n",
    "        self.b0 = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, u, y):\n",
    "        \"\"\"\n",
    "        Forward pass through DeepONet.\n",
    "\n",
    "        Args:\n",
    "            u: Branch input [batch_branch, u_dim]\n",
    "            y: Trunk input [batch_branch, n_points, coord_dim]\n",
    "\n",
    "        Returns:\n",
    "            Predictions [batch_branch, n_points]\n",
    "        \"\"\"\n",
    "\n",
    "        # Get branch and trunk latent representations\n",
    "        branch_output = self.branch_net(u)  # [batch_branch, p]\n",
    "        trunk_output = self.trunk_net(y)  # [batch_branch, n_points, p]\n",
    "\n",
    "        # Inner product operation\n",
    "        # We need to compute: sum over p dimension of (branch * trunk)\n",
    "        # branch_output: [batch_branch, p]\n",
    "        # trunk_output: [batch_branch, n_points, p]\n",
    "        # Goal: [batch_branch, n_points]\n",
    "\n",
    "        # Expand branch dimensions and element-wise multiply\n",
    "        branch_expanded = branch_output.unsqueeze(1)  # [batch_branch, 1, p]\n",
    "        s_pred = torch.sum(\n",
    "            branch_expanded * trunk_output, dim=-1\n",
    "        )  # [batch_branch, n_points]\n",
    "\n",
    "        # Add bias\n",
    "        s_pred = s_pred + self.b0\n",
    "\n",
    "        return s_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test networks\n",
    "test_branch = BranchNet(\n",
    "    input_dim=100, hidden_dim=64, output_dim=40, num_hidden_layers=2, activation=\"relu\"\n",
    ")\n",
    "test_trunk = TrunkNet(\n",
    "    input_dim=3, hidden_dim=64, output_dim=40, num_hidden_layers=2, activation=\"relu\"\n",
    ")\n",
    "test_model = DeepONet(test_branch, test_trunk)\n",
    "\n",
    "# Create random test data\n",
    "test_u = torch.randn(4, 100)  # [batch_branch=4, u_dim=100]\n",
    "test_y = torch.randn(4, 50, 3)  # [batch_branch=4, n_points=50, coord_dim=3]\n",
    "\n",
    "# Forward pass\n",
    "test_output = test_model(test_u, test_y)\n",
    "\n",
    "print(f\"Branch output shape: {test_branch(test_u).shape}\")\n",
    "print(f\"Trunk output shape: {test_trunk(test_y).shape}\")\n",
    "print(f\"DeepONet output shape: {test_output.shape}\")\n",
    "print(\"Expected output shape: [4, 50]\")\n",
    "\n",
    "assert test_output.shape == (4, 50), \"Output shape is incorrect!\"\n",
    "print(\"\\n✓ Test passed! Implementation is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deeponet(\n",
    "    model,\n",
    "    dataloader_train,\n",
    "    dataloader_val,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    device=\"cpu\",\n",
    "    grad_clip=None,\n",
    "    gamma=0.995,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train DeepONet model.\n",
    "\n",
    "    Args:\n",
    "        model: DeepONet instance\n",
    "        dataloader_train: Training data loader\n",
    "        dataloader_val: Validation data loader\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Initial learning rate for optimizer\n",
    "        device: 'cpu' or 'cuda'\n",
    "        grad_clip: Gradient clipping value (None = no clipping, 0.01 recommended for sine networks)\n",
    "        gamma: Decay rate for exponential learning rate schedule (default: 0.995)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with training history\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Setup learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"learning_rate\": []}\n",
    "\n",
    "    step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss_epoch = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch in dataloader_train:\n",
    "            (u, y), s_true, _, _ = batch\n",
    "            u, y, s_true = u.to(device), y.to(device), s_true.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            s_pred = model(u, y)\n",
    "            loss = criterion(s_pred, s_true)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            warmup_epochs = 5\n",
    "            if grad_clip is not None and epoch > warmup_epochs:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_epoch += loss.item()\n",
    "            num_batches += 1\n",
    "            step += 1\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        train_loss_epoch /= num_batches\n",
    "        history[\"train_loss\"].append(train_loss_epoch)\n",
    "\n",
    "        # Record current learning rate\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "        history[\"learning_rate\"].append(current_lr)\n",
    "\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            # Validating\n",
    "            model.eval()\n",
    "            val_loss_epoch = 0\n",
    "            num_val_batches = 0\n",
    "            with torch.no_grad():\n",
    "                for batch in dataloader_val:\n",
    "                    (u, y), s_true, _, _ = batch\n",
    "                    u, y, s_true = u.to(device), y.to(device), s_true.to(device)\n",
    "\n",
    "                    s_pred = model(u, y)\n",
    "                    loss = criterion(s_pred, s_true)\n",
    "\n",
    "                    val_loss_epoch += loss.item()\n",
    "                    num_val_batches += 1\n",
    "\n",
    "            val_loss_epoch /= num_val_batches\n",
    "            history[\"val_loss\"].append(val_loss_epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {train_loss_epoch:.6f}, Val Loss: {val_loss_epoch:.6f}, LR: {current_lr:.6f}\"\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {train_loss_epoch:.6f}, LR: {current_lr:.6f}\"\n",
    "            )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    \"\"\"Plot training and test loss over epochs.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.semilogy(history[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
    "    plt.semilogy(history[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"MSE Loss\", fontsize=12)\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim_branch = data_train.u_shape[0]  # From data\n",
    "input_dim_trunk = 3  # x, y, t coordinates\n",
    "hidden_dim = 2048\n",
    "output_dim = 100  # latent dimension p\n",
    "num_hidden_layers = 2\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 100\n",
    "\n",
    "grad_clip = None\n",
    "\n",
    "use_fourier_expansions = True\n",
    "use_sine = True  # otherwise relu\n",
    "angular_freq = 30\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history, label):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.semilogy(\n",
    "        history[\"train_loss\"], label=f\"f{label} - Train\", linewidth=2, linestyle=\"--\"\n",
    "    )\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Loss Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.semilogy(\n",
    "        history[\"val_loss\"], label=\"f{label} - Test\", linewidth=2, linestyle=\"--\"\n",
    "    )\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Validation Loss Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\nFinal Validation Loss:\")\n",
    "    print(f\"  f{label}: {history['val_loss'][-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fourier_expansions:\n",
    "    feat_fn_fourier = None\n",
    "    if use_sine:\n",
    "        # Create sine network WITH proper initialization\n",
    "        activation = \"sine\"\n",
    "        angular_freq = angular_freq\n",
    "    else:\n",
    "        activations = \"relu\"\n",
    "        angular_freq = None\n",
    "\n",
    "    # Create model with ReLU activation\n",
    "    branch = BranchNet(\n",
    "        input_dim_branch,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_hidden_layers,\n",
    "        activation=activation,\n",
    "        angular_freq=angular_freq,\n",
    "    )\n",
    "    trunk = TrunkNet(\n",
    "        input_dim_trunk,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_hidden_layers,\n",
    "        activation=activation,\n",
    "        angular_freq=angular_freq,\n",
    "    )\n",
    "    model = DeepONet(branch, trunk)\n",
    "\n",
    "    label_str = \"Sine\" if use_sine else \"ReLU\"\n",
    "    print(f\"\\nTraining model with {label_str} activation...\")\n",
    "    history_sine = train_deeponet(\n",
    "        model,\n",
    "        dataloader_train,\n",
    "        dataloader_val,\n",
    "        num_epochs,\n",
    "        learning_rate,\n",
    "        device,\n",
    "        grad_clip=grad_clip,\n",
    "    )\n",
    "\n",
    "    plot_losses(history_sine, label_str)\n",
    "else:\n",
    "    if use_sine:\n",
    "        # Create sine network WITH proper initialization\n",
    "        activation = \"sine\"\n",
    "        angular_freq = angular_freq\n",
    "    else:\n",
    "        activations = \"relu\"\n",
    "        angular_freq = None\n",
    "\n",
    "    # Create feature expansion functions\n",
    "    # use normalized frequencies\n",
    "    c_phys = 343\n",
    "    freq_norm = [166.7 / c_phys, 250 / c_phys, 500 / c_phys]\n",
    "    feat_fn_fourier = fourier_feature_expansion(freqs=freq_norm)\n",
    "\n",
    "    # Create datasets with different feature expansions\n",
    "    dataset_train_fourier = DatasetStreamer(\n",
    "        data_train, batch_size_coord=batch_size_coord, y_feat_extract_fn=feat_fn_fourier\n",
    "    )\n",
    "    dataset_test_fourier = DatasetStreamer(\n",
    "        data_val, batch_size_coord=-1, y_feat_extract_fn=feat_fn_fourier\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloader_train_fourier = DataLoader(\n",
    "        dataset_train_fourier,\n",
    "        batch_size=batch_size_branch,\n",
    "        shuffle=True,\n",
    "        collate_fn=pytorch_collate,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    dataloader_val_fourier = DataLoader(\n",
    "        dataset_test_fourier, batch_size=1, shuffle=False, collate_fn=pytorch_collate\n",
    "    )\n",
    "\n",
    "    # Get actual input dimensions\n",
    "    sample_fourier = next(iter(dataloader_train_fourier))\n",
    "    input_dim_trunk_fourier = sample_fourier[0][1].shape[-1]  # Should be 3 + 2*3*3 = 21\n",
    "\n",
    "    print(f\"Trunk input dim with Fourier features: {input_dim_trunk_fourier}\")\n",
    "\n",
    "    # Create models with Fourier features\n",
    "    branch_fourier = BranchNet(\n",
    "        input_dim_branch,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_hidden_layers,\n",
    "        activation=activation,\n",
    "    )\n",
    "    trunk_fourier = TrunkNet(\n",
    "        input_dim_trunk_fourier,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        num_hidden_layers,\n",
    "        activation=activation,\n",
    "    )\n",
    "    model = DeepONet(branch_fourier, trunk_fourier)\n",
    "\n",
    "    print(\"\\nTraining model WITH Fourier features...\")\n",
    "    history_fourier = train_deeponet(\n",
    "        model,\n",
    "        dataloader_train_fourier,\n",
    "        dataloader_val_fourier,\n",
    "        num_epochs,\n",
    "        learning_rate,\n",
    "        device,\n",
    "        grad_clip=grad_clip,\n",
    "    )\n",
    "\n",
    "    plot_losses(history_fourier, \"Fourier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "- ✓ Complete DeepONet implementation in PyTorch\n",
    "- ✓ Branch and trunk network architectures\n",
    "- ✓ Inner product operation for operator learning\n",
    "- ✓ Comparison of ReLU vs Sine activations\n",
    "- ✓ Impact of Fourier feature expansions\n",
    "- ✓ Full training and evaluation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Inference and Evaluation\n",
    "\n",
    "Now let's use the trained model to make predictions on test data and compare against ground truth.\n",
    "\n",
    "**Important**: The inference functions automatically detect whether you trained with Fourier features (`use_fourier_expansions = True`) and will use the appropriate model and feature extraction function. This ensures consistency between training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations\n",
    "\n",
    "The inference results demonstrate:\n",
    "\n",
    "1. **Full Wavefield Prediction**: The model can predict the entire pressure field across space and time for new source configurations not seen during training.\n",
    "\n",
    "2. **Impulse Response Accuracy**: By snapping receiver positions to the training grid using `utils.getNearestFromCoordinates`, we can accurately compare predictions with ground truth data.\n",
    "\n",
    "3. **Model Generalization**: The error metrics show how well the trained DeepONet generalizes to unseen test data, which is crucial for practical applications.\n",
    "\n",
    "4. **Computational Efficiency**: Once trained, the DeepONet can predict the full acoustic field much faster than running traditional PDE solvers, making it suitable for real-time applications or design optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = DataH5Compact(\n",
    "    test_data_path,\n",
    "    t_norm=343.0,\n",
    "    flatten_ic=True,\n",
    "    norm_data=True,\n",
    "    u_p_range=(-2.0, 2.0),\n",
    ")\n",
    "\n",
    "source_idx = 0\n",
    "\n",
    "print(f\"Test sources: {data_test.N}\")\n",
    "print(f\"Test source_idx: {source_idx}\")\n",
    "print(f\"Mesh points: {data_test.P_mesh}\")\n",
    "print(f\"Time steps: {len(data_test.tsteps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeponet_acoustics.utils.utils as utils\n",
    "\n",
    "\n",
    "def predict_impulse_response(\n",
    "    model,\n",
    "    data,\n",
    "    source_idx,\n",
    "    receiver_positions,\n",
    "    device=\"cpu\",\n",
    "    snap_to_grid=True,\n",
    "    y_feat_extract_fn=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict impulse response at specific receiver locations.\n",
    "\n",
    "    Args:\n",
    "        model: Trained DeepONet model\n",
    "        data: DataH5Compact instance\n",
    "        source_idx: Index of source\n",
    "        receiver_positions: List of receiver positions [[x1, y1], [x2, y2], ...]\n",
    "        device: Device to run predictions on\n",
    "        snap_to_grid: Whether to snap receiver positions to nearest grid points\n",
    "        y_feat_extract_fn: Optional feature extraction function for coordinates (e.g., Fourier features)\n",
    "\n",
    "    Returns:\n",
    "        ir_pred: Predicted impulse responses [n_receivers, time_steps]\n",
    "        ir_true: Ground truth impulse responses [n_receivers, time_steps] (if available)\n",
    "        receiver_pos_actual: Actual receiver positions (snapped if snap_to_grid=True)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get data for this source - but we'll manually create the coordinate array\n",
    "    dataset_single = DatasetStreamer(data, batch_size_coord=-1)\n",
    "    (u, _), s_true, _, x0 = dataset_single[source_idx]\n",
    "\n",
    "    # Get mesh in physical coordinates for snapping\n",
    "    mesh_phys = data.denormalize_spatial(data.mesh)\n",
    "\n",
    "    # Snap to grid if requested\n",
    "    if snap_to_grid:\n",
    "        receiver_positions_list = [receiver_positions]  # Wrap for utils function\n",
    "        receiver_pos_actual, receiver_indices = utils.getNearestFromCoordinates(\n",
    "            mesh_phys, receiver_positions_list\n",
    "        )\n",
    "        receiver_pos_actual = receiver_pos_actual[0]\n",
    "        receiver_indices = receiver_indices[0]\n",
    "    else:\n",
    "        receiver_pos_actual = np.array(receiver_positions)\n",
    "        receiver_indices = None\n",
    "\n",
    "    # Normalize receiver positions for model input\n",
    "    receiver_pos_norm = data.normalize_spatial(receiver_pos_actual)\n",
    "\n",
    "    # Create coordinate array: repeat each receiver position for all time steps\n",
    "    n_receivers = len(receiver_pos_norm)\n",
    "    tdim = len(data.tsteps)\n",
    "\n",
    "    y_rcvs = np.repeat(receiver_pos_norm, tdim, axis=0)  # [n_receivers*tdim, 2]\n",
    "    tsteps_rcvs = np.tile(data.tsteps, n_receivers)  # [n_receivers*tdim]\n",
    "    y_input = np.concatenate(\n",
    "        (y_rcvs, np.expand_dims(tsteps_rcvs, 1)), axis=1\n",
    "    )  # [n_receivers*tdim, 3]\n",
    "\n",
    "    # Apply feature extraction if provided (e.g., Fourier features)\n",
    "    if y_feat_extract_fn is not None:\n",
    "        y_input = y_feat_extract_fn(y_input)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    u_torch = torch.from_numpy(u).float().unsqueeze(0).to(device)  # [1, u_dim]\n",
    "    y_torch = (\n",
    "        torch.from_numpy(y_input).float().unsqueeze(0).to(device)\n",
    "    )  # [1, n_receivers*tdim, coord_dim]\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        ir_pred_flat = model(u_torch, y_torch)  # [1, n_receivers*tdim]\n",
    "        ir_pred = (\n",
    "            ir_pred_flat.cpu().numpy().reshape(n_receivers, tdim).T\n",
    "        )  # [tdim, n_receivers]\n",
    "\n",
    "    # Extract ground truth if snapped to grid\n",
    "    if snap_to_grid and receiver_indices is not None:\n",
    "        s_true_reshaped = s_true.reshape(tdim, -1)\n",
    "        ir_true = s_true_reshaped[:, receiver_indices]  # [tdim, n_receivers]\n",
    "    else:\n",
    "        ir_true = None\n",
    "\n",
    "    return ir_pred, ir_true, receiver_pos_actual\n",
    "\n",
    "\n",
    "# Define receiver positions (in physical coordinates)\n",
    "receiver_positions = [\n",
    "    [1.0, 1.0],  # Center\n",
    "    [0.5, 1.5],  # Top left\n",
    "    [1.5, 0.5],  # Bottom right\n",
    "]\n",
    "\n",
    "# Predict impulse responses - use same model and features as for full wavefield\n",
    "ir_pred, ir_true, receiver_pos_actual = predict_impulse_response(\n",
    "    model,\n",
    "    data_test,\n",
    "    source_idx,\n",
    "    receiver_positions,\n",
    "    device,\n",
    "    snap_to_grid=True,\n",
    "    y_feat_extract_fn=feat_fn_fourier,\n",
    ")\n",
    "\n",
    "print(f\"Predicted IR shape: {ir_pred.shape}\")\n",
    "print(f\"Ground truth IR shape: {ir_true.shape}\")\n",
    "print(\"\\nReceiver positions (snapped to grid):\")\n",
    "for i, pos in enumerate(receiver_pos_actual):\n",
    "    print(f\"  Receiver {i + 1}: [{pos[0]:.3f}, {pos[1]:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_impulse_responses(\n",
    "    data, ir_pred, ir_true, receiver_positions, figsize=(15, 10)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot impulse responses at receiver locations.\n",
    "\n",
    "    Args:\n",
    "        data: DataH5Compact instance\n",
    "        ir_pred: Predicted impulse responses [time_steps, n_receivers]\n",
    "        ir_true: Ground truth impulse responses [time_steps, n_receivers]\n",
    "        receiver_positions: Receiver positions [[x1, y1], [x2, y2], ...]\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    n_receivers = ir_pred.shape[1]\n",
    "    tsteps_phys = data.denormalize_temporal(\n",
    "        data.tsteps / 343.0\n",
    "    )  # Convert to physical time\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    gs = fig.add_gridspec(2, n_receivers, height_ratios=[1, 2], hspace=0.3, wspace=0.3)\n",
    "\n",
    "    # Top row: Receiver positions on mesh\n",
    "    ax_mesh = fig.add_subplot(gs[0, :])\n",
    "\n",
    "    # Plot mesh\n",
    "    ax_mesh.scatter(data.mesh[:, 0], data.mesh[:, 1], c=\"lightgray\", s=1, alpha=0.3)\n",
    "\n",
    "    # Plot receiver positions\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_receivers))\n",
    "    for i, (pos, color) in enumerate(zip(receiver_positions, colors)):\n",
    "        # Normalize for plotting\n",
    "        pos_norm = data.normalize_spatial(np.array([pos]))[0]\n",
    "        ax_mesh.scatter(\n",
    "            pos_norm[0],\n",
    "            pos_norm[1],\n",
    "            c=[color],\n",
    "            s=200,\n",
    "            marker=\"o\",\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=2,\n",
    "            label=f\"Receiver {i + 1}\",\n",
    "            zorder=5,\n",
    "        )\n",
    "\n",
    "    ax_mesh.set_xlabel(\"x [m]\")\n",
    "    ax_mesh.set_ylabel(\"y [m]\")\n",
    "    ax_mesh.set_title(\"Receiver Positions\")\n",
    "    ax_mesh.set_aspect(\"equal\")\n",
    "    ax_mesh.legend(loc=\"upper right\")\n",
    "    ax_mesh.grid(True, alpha=0.3)\n",
    "\n",
    "    # Bottom row: Impulse responses\n",
    "    for i in range(n_receivers):\n",
    "        ax = fig.add_subplot(gs[1, i])\n",
    "\n",
    "        # Plot ground truth and prediction\n",
    "        if ir_true is not None:\n",
    "            ax.plot(\n",
    "                tsteps_phys,\n",
    "                ir_true[:, i],\n",
    "                \"k-\",\n",
    "                linewidth=2,\n",
    "                label=\"Ground Truth\",\n",
    "                alpha=0.7,\n",
    "            )\n",
    "        ax.plot(\n",
    "            tsteps_phys,\n",
    "            ir_pred[:, i],\n",
    "            \"--\",\n",
    "            color=colors[i],\n",
    "            linewidth=2,\n",
    "            label=\"Prediction\",\n",
    "        )\n",
    "\n",
    "        ax.set_xlabel(\"Time [s]\")\n",
    "        ax.set_ylabel(\"Pressure\")\n",
    "        ax.set_title(\n",
    "            f\"Receiver {i + 1}: [{receiver_positions[i][0]:.2f}, {receiver_positions[i][1]:.2f}]\"\n",
    "        )\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Compute error metrics if ground truth available\n",
    "        if ir_true is not None:\n",
    "            mse = np.mean((ir_pred[:, i] - ir_true[:, i]) ** 2)\n",
    "            mae = np.mean(np.abs(ir_pred[:, i] - ir_true[:, i]))\n",
    "            ax.text(\n",
    "                0.02,\n",
    "                0.98,\n",
    "                f\"MSE: {mse:.6f}\\nMAE: {mae:.6f}\",\n",
    "                transform=ax.transAxes,\n",
    "                verticalalignment=\"top\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.5),\n",
    "            )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot impulse responses\n",
    "plot_impulse_responses(data_test, ir_pred, ir_true, receiver_pos_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impulse Response at Specific Receiver Locations\n",
    "\n",
    "Now let's predict the impulse response (pressure over time) at specific receiver locations and compare with ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_full_wavefield(\n",
    "    model, data, source_idx=0, device=\"cpu\", y_feat_extract_fn=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Predict full wavefield for a single source.\n",
    "\n",
    "    Args:\n",
    "        model: Trained DeepONet model\n",
    "        data: DataH5Compact instance\n",
    "        source_idx: Index of source to predict\n",
    "        device: Device to run predictions on\n",
    "        y_feat_extract_fn: Optional feature extraction function for coordinates (e.g., Fourier features)\n",
    "\n",
    "    Returns:\n",
    "        s_pred: Predicted pressure field [time_steps, mesh_points]\n",
    "        s_true: Ground truth pressure field [time_steps, mesh_points]\n",
    "        u: Initial condition\n",
    "        x0: Source position\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get data for this source - apply same feature extraction as during training\n",
    "    dataset_single = DatasetStreamer(\n",
    "        data, batch_size_coord=-1, y_feat_extract_fn=y_feat_extract_fn\n",
    "    )\n",
    "    (u, y), s_true, _, x0 = dataset_single[source_idx]\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    u = torch.from_numpy(u).float().unsqueeze(0).to(device)  # [1, u_dim]\n",
    "    y = torch.from_numpy(y).float().unsqueeze(0).to(device)  # [1, n_points, coord_dim]\n",
    "\n",
    "    tdim = len(data.tsteps)\n",
    "    n_mesh = data.P_mesh\n",
    "\n",
    "    # Predict for all time steps\n",
    "    with torch.no_grad():\n",
    "        s_pred = model(u, y)  # [1, n_points]\n",
    "        s_pred = s_pred.cpu().numpy().reshape(tdim, n_mesh)\n",
    "\n",
    "    s_true = s_true.reshape(tdim, n_mesh)\n",
    "\n",
    "    return s_pred, s_true, u.cpu().numpy().squeeze(), x0\n",
    "\n",
    "\n",
    "# Predict for first test source\n",
    "source_idx = 0\n",
    "s_pred, s_true, u_test, x0 = predict_full_wavefield(\n",
    "    model, data_test, source_idx, device, y_feat_extract_fn=feat_fn_fourier\n",
    ")\n",
    "\n",
    "print(f\"Predicted wavefield shape: {s_pred.shape}\")\n",
    "print(f\"Ground truth wavefield shape: {s_true.shape}\")\n",
    "print(f\"Source position: {x0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wavefield_comparison(\n",
    "    data, s_pred, s_true, source_idx=0, time_indices=[20, 40, 60, 80], figsize=(16, 8)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot comparison between predicted and ground truth wavefields.\n",
    "\n",
    "    Args:\n",
    "        data: DataH5Compact instance\n",
    "        s_pred: Predicted pressure field [time_steps, mesh_points]\n",
    "        s_true: Ground truth pressure field [time_steps, mesh_points]\n",
    "        source_idx: Index of source\n",
    "        time_indices: List of time step indices to plot\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    n_plots = len(time_indices)\n",
    "    fig, axes = plt.subplots(3, n_plots, figsize=figsize)\n",
    "\n",
    "    vmin, vmax = -0.5, 0.5\n",
    "\n",
    "    dataset = data.datasets[source_idx]\n",
    "\n",
    "    for i, t_idx in enumerate(time_indices):\n",
    "        # Ground truth\n",
    "        scatter1 = axes[0, i].scatter(\n",
    "            data.mesh[:, 0],\n",
    "            data.mesh[:, 1],\n",
    "            c=s_true[t_idx, :],\n",
    "            cmap=\"RdBu_r\",\n",
    "            s=10,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        axes[0, i].set_title(f\"t_norm = {data.tsteps[t_idx]:.2f}\")\n",
    "        axes[0, i].set_aspect(\"equal\")\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel(\"Ground Truth\\ny [m]\")\n",
    "\n",
    "        # Prediction\n",
    "        scatter2 = axes[1, i].scatter(\n",
    "            data.mesh[:, 0],\n",
    "            data.mesh[:, 1],\n",
    "            c=s_pred[t_idx, :],\n",
    "            cmap=\"RdBu_r\",\n",
    "            s=10,\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "        )\n",
    "        axes[1, i].set_aspect(\"equal\")\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel(\"Prediction\\ny [m]\")\n",
    "\n",
    "        # Error\n",
    "        error = np.abs(s_pred[t_idx, :] - s_true[t_idx, :])\n",
    "        scatter3 = axes[2, i].scatter(\n",
    "            data.mesh[:, 0],\n",
    "            data.mesh[:, 1],\n",
    "            c=error,\n",
    "            cmap=\"hot\",\n",
    "            s=10,\n",
    "            vmin=0,\n",
    "            vmax=0.1,\n",
    "        )\n",
    "        axes[2, i].set_xlabel(\"x [m]\")\n",
    "        axes[2, i].set_aspect(\"equal\")\n",
    "        if i == 0:\n",
    "            axes[2, i].set_ylabel(\"Absolute Error\\ny [m]\")\n",
    "\n",
    "        # Mark source position\n",
    "        if \"source_position\" in dataset:\n",
    "            x0 = dataset[\"source_position\"][:]\n",
    "            if data.normalize_data:\n",
    "                from deeponet_acoustics.datahandlers.datagenerators import (\n",
    "                    _normalize_spatial,\n",
    "                )\n",
    "\n",
    "                x0 = _normalize_spatial(x0, data.xmin_phys, data.xmax_phys)\n",
    "            for ax_row in axes[:, i]:\n",
    "                ax_row.plot(x0[0], x0[1], \"k*\", markersize=10)\n",
    "\n",
    "    # Add colorbars\n",
    "    fig.colorbar(scatter1, ax=axes[0, :], label=\"Pressure\", pad=0.02, fraction=0.046)\n",
    "    fig.colorbar(scatter2, ax=axes[1, :], label=\"Pressure\", pad=0.02, fraction=0.046)\n",
    "    fig.colorbar(scatter3, ax=axes[2, :], label=\"|Error|\", pad=0.02, fraction=0.046)\n",
    "\n",
    "    fig.suptitle(f\"Wavefield Comparison (Source {source_idx})\", y=0.995, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Compute and print metrics\n",
    "    mse = np.mean((s_pred - s_true) ** 2)\n",
    "    mae = np.mean(np.abs(s_pred - s_true))\n",
    "    max_error = np.max(np.abs(s_pred - s_true))\n",
    "\n",
    "    print(\"Prediction Metrics:\")\n",
    "    print(f\"  MSE: {mse:.6f}\")\n",
    "    print(f\"  MAE: {mae:.6f}\")\n",
    "    print(f\"  Max Error: {max_error:.6f}\")\n",
    "\n",
    "\n",
    "# Plot comparison\n",
    "plot_wavefield_comparison(\n",
    "    data_test, s_pred, s_true, source_idx, time_indices=[20, 40, 60, 80]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Questions\n",
    "\n",
    "After running the experiments, discuss:\n",
    "\n",
    "1. **Activation Functions**:\n",
    "   - Which activation (ReLU vs Sine) performed better? Why might this be?\n",
    "   - How did convergence speed differ between the two?\n",
    "   - What physical properties of acoustic waves might favor one activation over another?\n",
    "\n",
    "2. **Fourier Features**:\n",
    "   - Did Fourier features improve performance? By how much?\n",
    "   - What is the computational cost of Fourier features (hint: look at input dimensions)?\n",
    "   - When would you recommend using Fourier features?\n",
    "\n",
    "3. **DeepONet Architecture**:\n",
    "   - Why is the operator learning approach useful for PDEs?\n",
    "   - What are the advantages of DeepONet vs traditional PDE solvers?\n",
    "   - What are the limitations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
